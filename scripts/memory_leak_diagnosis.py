#!/usr/bin/env python3
"""
å†…å­˜å’Œæ˜¾å­˜æ³„æ¼è¯Šæ–­è„šæœ¬
ç”¨äºåˆ†æç³»ç»Ÿä¸­è¿›ç¨‹ã€å†…å­˜å’ŒGPUèµ„æºçš„ä½¿ç”¨æƒ…å†µï¼Œæ‰¾å‡ºæ½œåœ¨çš„èµ„æºæ³„æ¼é—®é¢˜
"""

import os
import sys
import time
import subprocess
import psutil
import logging
from typing import Dict, List, Optional
import json

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class ResourceLeakDetector:
    """èµ„æºæ³„æ¼æ£€æµ‹å™¨"""

    def __init__(self):
        self.process_snapshots = []
        self.gpu_snapshots = []

    def get_process_info(self) -> Dict:
        """è·å–å½“å‰è¿›ç¨‹ä¿¡æ¯"""
        try:
            # è·å–Pythonè¿›ç¨‹ä¿¡æ¯
            python_processes = []
            for proc in psutil.process_iter(['pid', 'name', 'cpu_percent', 'memory_percent', 'memory_info']):
                try:
                    if 'python' in proc.info['name'].lower():
                        python_processes.append({
                            'pid': proc.info['pid'],
                            'name': proc.info['name'],
                            'cpu_percent': proc.info['cpu_percent'],
                            'memory_percent': proc.info['memory_percent'],
                            'memory_rss': proc.info['memory_info'].rss / 1024 / 1024,  # MB
                            'memory_vms': proc.info['memory_info'].vms / 1024 / 1024,  # MB
                            'cmdline': ' '.join(proc.cmdline()) if proc.cmdline() else 'N/A'
                        })
                except (psutil.NoSuchProcess, psutil.AccessDenied):
                    continue

            # è·å–ç³»ç»Ÿæ€»å†…å­˜ä¿¡æ¯
            memory = psutil.virtual_memory()

            return {
                'timestamp': time.time(),
                'python_processes': python_processes,
                'system_memory': {
                    'total': memory.total / 1024 / 1024 / 1024,  # GB
                    'available': memory.available / 1024 / 1024 / 1024,  # GB
                    'used': memory.used / 1024 / 1024 / 1024,  # GB
                    'percent': memory.percent
                }
            }
        except Exception as e:
            logger.error(f"è·å–è¿›ç¨‹ä¿¡æ¯å¤±è´¥: {e}")
            return {}

    def get_gpu_info(self) -> Dict:
        """è·å–GPUä¿¡æ¯"""
        try:
            # ä½¿ç”¨nvidia-smiè·å–GPUä¿¡æ¯
            result = subprocess.run(
                ['nvidia-smi', '--query-gpu=name,memory.total,memory.used,memory.free,utilization.gpu,temperature.gpu',
                 '--format=csv,noheader,nounits'],
                capture_output=True, text=True, check=True
            )

            gpu_info = {}
            for i, line in enumerate(result.stdout.strip().split('\n')):
                if line.strip():
                    parts = [p.strip() for p in line.split(',')]
                    gpu_info[f'gpu_{i}'] = {
                        'name': parts[0],
                        'memory_total': int(parts[1]),  # MB
                        'memory_used': int(parts[2]),  # MB
                        'memory_free': int(parts[3]),  # MB
                        'utilization': int(parts[4]),  # %
                        'temperature': int(parts[5])  # Â°C
                    }

            # è·å–è¿›ç¨‹ä¿¡æ¯
            try:
                result_processes = subprocess.run(
                    ['nvidia-smi', '--query-compute-apps=pid,process_name,used_memory',
                     '--format=csv,noheader,nounits'],
                    capture_output=True, text=True, check=True
                )

                processes = []
                for line in result_processes.stdout.strip().split('\n'):
                    if line.strip():
                        parts = [p.strip() for p in line.split(',')]
                        processes.append({
                            'pid': int(parts[0]),
                            'process_name': parts[1],
                            'used_memory': int(parts[2])  # MB
                        })

                gpu_info['processes'] = processes
            except subprocess.CalledProcessError:
                gpu_info['processes'] = []

            return {
                'timestamp': time.time(),
                'gpu_info': gpu_info
            }
        except subprocess.CalledProcessError as e:
            logger.warning(f"è·å–GPUä¿¡æ¯å¤±è´¥: {e}")
            return {}
        except FileNotFoundError:
            logger.warning("nvidia-smi å‘½ä»¤æœªæ‰¾åˆ°ï¼Œå¯èƒ½æ²¡æœ‰NVIDIA GPU")
            return {}

    def analyze_python_multiprocessing(self) -> Dict:
        """åˆ†æPythonå¤šè¿›ç¨‹æƒ…å†µ"""
        try:
            # æŸ¥æ‰¾multiprocessingç›¸å…³çš„è¿›ç¨‹
            result = subprocess.run(
                ['ps', 'aux'], capture_output=True, text=True
            )

            multiprocessing_processes = []
            for line in result.stdout.split('\n'):
                if 'multiprocessing' in line or 'spawn_main' in line or 'resource_tracker' in line:
                    parts = line.split()
                    if len(parts) >= 11:
                        multiprocessing_processes.append({
                            'user': parts[0],
                            'pid': parts[1],
                            'cpu': parts[2],
                            'mem': parts[3],
                            'command': ' '.join(parts[10:])
                        })

            return {
                'multiprocessing_processes': multiprocessing_processes,
                'total_count': len(multiprocessing_processes)
            }
        except Exception as e:
            logger.error(f"åˆ†æå¤šè¿›ç¨‹å¤±è´¥: {e}")
            return {}

    def detect_leak_patterns(self) -> Dict:
        """æ£€æµ‹æ³„æ¼æ¨¡å¼"""
        leak_analysis = {
            'potential_leaks': [],
            'warnings': [],
            'recommendations': []
        }

        # åˆ†æå¤šè¿›ç¨‹æƒ…å†µ
        mp_analysis = self.analyze_python_multiprocessing()
        if mp_analysis.get('total_count', 0) > 10:
            leak_analysis['warnings'].append(f"æ£€æµ‹åˆ°å¤§é‡å¤šè¿›ç¨‹: {mp_analysis['total_count']} ä¸ª")
            leak_analysis['recommendations'].append("æ£€æŸ¥æ˜¯å¦æœ‰æœªæ­£ç¡®æ¸…ç†çš„multiprocessingè¿›ç¨‹")

        # åˆ†æPythonè¿›ç¨‹å†…å­˜ä½¿ç”¨
        process_info = self.get_process_info()
        for proc in process_info.get('python_processes', []):
            if proc['memory_rss'] > 2000:  # è¶…è¿‡2GB
                leak_analysis['potential_leaks'].append(
                    f"é«˜å†…å­˜è¿›ç¨‹: PID {proc['pid']} ({proc['name']}) - {proc['memory_rss']:.1f}MB"
                )

        # åˆ†æGPUæ˜¾å­˜ä½¿ç”¨
        gpu_info = self.get_gpu_info()
        for gpu_key, gpu_data in gpu_info.get('gpu_info', {}).items():
            if gpu_key.startswith('gpu_'):
                memory_usage_percent = (gpu_data['memory_used'] / gpu_data['memory_total']) * 100
                if memory_usage_percent > 80:
                    leak_analysis['warnings'].append(
                        f"GPU {gpu_key} æ˜¾å­˜ä½¿ç”¨ç‡è¿‡é«˜: {memory_usage_percent:.1f}%"
                    )

                # æ£€æŸ¥æ˜¯å¦æœ‰åƒµå°¸GPUè¿›ç¨‹
                gpu_processes = gpu_info.get('processes', [])
                if len(gpu_processes) == 0 and gpu_data['memory_used'] > 1000:  # æ²¡æœ‰è¿›ç¨‹ä½†æ˜¾å­˜è¢«å ç”¨
                    leak_analysis['potential_leaks'].append(
                        f"GPU {gpu_key} å¯èƒ½æœ‰æ˜¾å­˜æ³„æ¼: {gpu_data['memory_used']}MB è¢«å ç”¨ä½†æ²¡æœ‰æ´»è·ƒè¿›ç¨‹"
                    )

        return leak_analysis

    def generate_report(self) -> str:
        """ç”Ÿæˆè¯Šæ–­æŠ¥å‘Š"""
        report_lines = [
            "=" * 80,
            "å†…å­˜å’Œæ˜¾å­˜æ³„æ¼è¯Šæ–­æŠ¥å‘Š",
            f"ç”Ÿæˆæ—¶é—´: {time.strftime('%Y-%m-%d %H:%M:%S')}",
            "=" * 80,
            ""
        ]

        # è¿›ç¨‹ä¿¡æ¯
        process_info = self.get_process_info()
        report_lines.extend([
            "ğŸ“Š ç³»ç»Ÿè¿›ç¨‹ä¿¡æ¯",
            "-" * 40,
            f"ç³»ç»Ÿå†…å­˜ä½¿ç”¨: {process_info.get('system_memory', {}).get('used', 0):.1f}GB / {process_info.get('system_memory', {}).get('total', 0):.1f}GB ({process_info.get('system_memory', {}).get('percent', 0):.1f}%)",
            f"Pythonè¿›ç¨‹æ•°é‡: {len(process_info.get('python_processes', []))}",
            ""
        ])

        # é«˜å†…å­˜è¿›ç¨‹
        high_memory_processes = [p for p in process_info.get('python_processes', []) if p['memory_rss'] > 1000]
        if high_memory_processes:
            report_lines.extend([
                "ğŸ”´ é«˜å†…å­˜ä½¿ç”¨è¿›ç¨‹ (>1GB):",
                "-" * 40
            ])
            for proc in high_memory_processes[:5]:  # åªæ˜¾ç¤ºå‰5ä¸ª
                report_lines.append(f"  PID {proc['pid']:>8}: {proc['memory_rss']:.1f}MB ({proc['memory_percent']:.1f}%) - {proc['cmdline'][:80]}")
            report_lines.append("")

        # GPUä¿¡æ¯
        gpu_info = self.get_gpu_info()
        if gpu_info.get('gpu_info'):
            report_lines.extend([
                "ğŸ® GPUä¿¡æ¯",
                "-" * 40
            ])
            for gpu_key, gpu_data in gpu_info.get('gpu_info', {}).items():
                if gpu_key.startswith('gpu_'):
                    memory_usage_percent = (gpu_data['memory_used'] / gpu_data['memory_total']) * 100
                    report_lines.extend([
                        f"  {gpu_key.upper()}: {gpu_data['name']}",
                        f"    æ˜¾å­˜: {gpu_data['memory_used']}MB / {gpu_data['memory_total']}MB ({memory_usage_percent:.1f}%)",
                        f"    åˆ©ç”¨ç‡: {gpu_data['utilization']}%, æ¸©åº¦: {gpu_data['temperature']}Â°C"
                    ])

            gpu_processes = gpu_info.get('processes', [])
            if gpu_processes:
                report_lines.extend([
                    "",
                    "  GPUè¿›ç¨‹:",
                ])
                for proc in gpu_processes:
                    report_lines.append(f"    PID {proc['pid']}: {proc['process_name']} ({proc['used_memory']}MB)")
            report_lines.append("")

        # å¤šè¿›ç¨‹åˆ†æ
        mp_analysis = self.analyze_python_multiprocessing()
        if mp_analysis.get('total_count', 0) > 0:
            report_lines.extend([
                "ğŸ”„ å¤šè¿›ç¨‹åˆ†æ",
                "-" * 40,
                f"Multiprocessingè¿›ç¨‹æ€»æ•°: {mp_analysis['total_count']}",
                ""
            ])

            if mp_analysis.get('multiprocessing_processes'):
                report_lines.extend(["è¿›ç¨‹è¯¦æƒ…:"])
                for proc in mp_analysis['multiprocessing_processes'][:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                    report_lines.append(f"  {proc['pid']:>8} {proc['cpu']:>5}% {proc['mem']:>5}% {proc['command'][:60]}")
                report_lines.append("")

        # æ³„æ¼æ£€æµ‹
        leak_analysis = self.detect_leak_patterns()
        report_lines.extend([
            "ğŸš¨ æ³„æ¼æ£€æµ‹åˆ†æ",
            "-" * 40
        ])

        if leak_analysis['potential_leaks']:
            report_lines.extend([
                "âš ï¸  æ½œåœ¨æ³„æ¼:",
                *[f"  - {leak}" for leak in leak_analysis['potential_leaks']],
                ""
            ])

        if leak_analysis['warnings']:
            report_lines.extend([
                "âš¡ è­¦å‘Š:",
                *[f"  - {warning}" for warning in leak_analysis['warnings']],
                ""
            ])

        if leak_analysis['recommendations']:
            report_lines.extend([
                "ğŸ’¡ å»ºè®®:",
                *[f"  - {rec}" for rec in leak_analysis['recommendations']],
                ""
            ])

        # ä¿®å¤å»ºè®®
        report_lines.extend([
            "ğŸ”§ ä¿®å¤å»ºè®®",
            "-" * 40,
            "1. æ£€æŸ¥Pythonåº”ç”¨ä¸­çš„èµ„æºæ¸…ç†é€»è¾‘",
            "2. ç¡®ä¿æ‰€æœ‰GPUæ¨¡å‹å’Œtensoråœ¨ä½¿ç”¨åè¢«æ­£ç¡®é‡Šæ”¾",
            "3. æ£€æŸ¥multiprocessingè¿›ç¨‹æ˜¯å¦æ­£ç¡®join()å’Œterminate()",
            "4. è€ƒè™‘ä½¿ç”¨torch.cuda.empty_cache()å®šæœŸæ¸…ç†GPUç¼“å­˜",
            "5. ç›‘æ§é•¿æ—¶é—´è¿è¡Œåº”ç”¨çš„å†…å­˜å¢é•¿è¶‹åŠ¿",
            ""
        ])

        return "\n".join(report_lines)

    def save_report(self, filename: str = None) -> str:
        """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
        if filename is None:
            filename = f"/tmp/memory_leak_report_{int(time.time())}.txt"

        report = self.generate_report()
        with open(filename, 'w', encoding='utf-8') as f:
            f.write(report)

        logger.info(f"è¯Šæ–­æŠ¥å‘Šå·²ä¿å­˜åˆ°: {filename}")
        return filename

def main():
    """ä¸»å‡½æ•°"""
    logger.info("å¼€å§‹å†…å­˜å’Œæ˜¾å­˜æ³„æ¼è¯Šæ–­...")

    detector = ResourceLeakDetector()

    # ç”Ÿæˆå¹¶ä¿å­˜æŠ¥å‘Š
    report_file = detector.save_report()

    # æ‰“å°æŠ¥å‘Šåˆ°æ§åˆ¶å°
    report_content = detector.generate_report()
    print(report_content)

    logger.info("è¯Šæ–­å®Œæˆ")

if __name__ == "__main__":
    main()