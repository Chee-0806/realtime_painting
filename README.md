# StreamDiffusion Backend

åŸºäº StreamDiffusion çš„å®æ—¶å›¾åƒç”Ÿæˆåç«¯æœåŠ¡ï¼Œä¸ºå‰ç«¯æä¾›é«˜æ€§èƒ½çš„ AI å›¾åƒç”Ÿæˆèƒ½åŠ›ã€‚

## ç‰¹æ€§

- âš¡ **å®æ—¶ç”Ÿæˆ**ï¼šåŸºäº StreamDiffusion ä¼˜åŒ–ï¼Œå•å¸§å»¶è¿Ÿ < 100ms
- ğŸš€ **å¤šç§åŠ é€Ÿ**ï¼šæ”¯æŒ xformersã€TensorRT ç­‰åŠ é€Ÿæ–¹å¼
- ğŸ¨ **åŒæ¨¡å¼æ”¯æŒ**ï¼šImage Mode (img2img) å’Œ Video Mode (txt2img)
- ğŸ”Œ **WebSocket é€šä¿¡**ï¼šä½å»¶è¿Ÿçš„åŒå‘å®æ—¶é€šä¿¡
- ğŸ“¡ **HTTP å›¾åƒæµ**ï¼šé€šè¿‡ multipart/x-mixed-replace æŒç»­æ¨é€
- ğŸ”§ **çµæ´»é…ç½®**ï¼šYAML é…ç½®æ–‡ä»¶ + ç¯å¢ƒå˜é‡
- ğŸ³ **Docker æ”¯æŒ**ï¼šä¸€é”®éƒ¨ç½²ï¼Œæ”¯æŒ NVIDIA GPU

## ç³»ç»Ÿè¦æ±‚

- **æ“ä½œç³»ç»Ÿ**ï¼šLinux (Ubuntu 20.04+)
- **Python**ï¼š3.10+
- **CUDA**ï¼š11.8+ æˆ– 12.1+
- **GPU**ï¼šNVIDIA GPU with 8GB+ VRAM
- **å†…å­˜**ï¼š16GB+ RAM
- **ç£ç›˜ç©ºé—´**ï¼š20GB+

## å¿«é€Ÿå¼€å§‹

### 1. å…‹éš†ä»“åº“

```bash
git clone <repository-url>
cd streamdiffusion-backend
```

### 2. å®‰è£…ä¾èµ–

```bash
# åˆ›å»ºè™šæ‹Ÿç¯å¢ƒ
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# æˆ– venv\Scripts\activate  # Windows

# å®‰è£…æ ¸å¿ƒä¾èµ–
pip install -r requirements.txt

# é€‰æ‹©åŠ é€Ÿæ–¹å¼ï¼ˆäºŒé€‰ä¸€ï¼‰
pip install -r requirements-xformers.txt  # æ¨èï¼šxformers
# æˆ–
pip install -r requirements-tensorrt.txt  # TensorRTï¼ˆéœ€è¦æ›´å¤šé…ç½®ï¼‰
```

### 3. é…ç½®

å¤åˆ¶é…ç½®æ–‡ä»¶å¹¶æ ¹æ®éœ€è¦ä¿®æ”¹ï¼š

```bash
cp .env.example .env
```

ç¼–è¾‘ `app/config/config.yaml` é…ç½®æ¨¡å‹å’Œå‚æ•°ï¼š

```yaml
model:
  model_id: "stabilityai/sd-turbo"
  acceleration: "xformers"  # xformers | tensorrt | none

pipeline:
  name: "img2img"
  mode: "image"  # image | video
  width: 512
  height: 512
```

### 4. è¿è¡ŒæœåŠ¡

```bash
python -m uvicorn app.main:app --host 0.0.0.0 --port 8000
```

æˆ–ä½¿ç”¨ Python ç›´æ¥è¿è¡Œï¼š

```bash
python -m app.main
```

æœåŠ¡å°†åœ¨ `http://localhost:8000` å¯åŠ¨ã€‚

## Docker éƒ¨ç½²

### ä½¿ç”¨ Docker Composeï¼ˆæ¨èï¼‰

```bash
# æ„å»ºå¹¶å¯åŠ¨
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f

# åœæ­¢æœåŠ¡
docker-compose down
```

### ä½¿ç”¨ Docker

```bash
# æ„å»ºé•œåƒ
docker build -t streamdiffusion-backend .

# è¿è¡Œå®¹å™¨
docker run -d \
  --name streamdiffusion-backend \
  --gpus all \
  -p 8000:8000 \
  -v $(pwd)/engines:/app/engines \
  streamdiffusion-backend
```

## API æ–‡æ¡£

### WebSocket API

è¿æ¥åˆ° `/api/ws/{userId}` è¿›è¡Œå®æ—¶é€šä¿¡ã€‚

**åè®®æµç¨‹**ï¼š

1. å®¢æˆ·ç«¯è¿æ¥ â†’ æœåŠ¡å™¨å‘é€ `{"status": "connected"}`
2. æœåŠ¡å™¨å‘é€ `{"status": "send_frame"}`
3. å®¢æˆ·ç«¯å‘é€ `{"status": "next_frame"}`
4. å®¢æˆ·ç«¯å‘é€å‚æ•° JSONï¼š`{"prompt": "...", "guidance_scale": 7.5, ...}`
5. å®¢æˆ·ç«¯å‘é€å›¾åƒæ•°æ®ï¼ˆä»… image æ¨¡å¼ï¼‰
6. é‡å¤æ­¥éª¤ 2-5

**ç¤ºä¾‹ï¼ˆJavaScriptï¼‰**ï¼š

```javascript
const ws = new WebSocket('ws://localhost:8000/api/ws/user123?mode=image');

ws.onmessage = async (event) => {
  const data = JSON.parse(event.data);
  
  if (data.status === 'send_frame') {
    // å‘é€ next_frame æ¶ˆæ¯
    ws.send(JSON.stringify({ status: 'next_frame' }));
    
    // å‘é€å‚æ•°
    ws.send(JSON.stringify({
      prompt: 'a beautiful landscape',
      guidance_scale: 7.5,
      num_inference_steps: 4
    }));
    
    // å‘é€å›¾åƒï¼ˆå¦‚æœæ˜¯ image æ¨¡å¼ï¼‰
    const imageBlob = await captureImage();
    ws.send(imageBlob);
  }
};
```

### HTTP API

#### GET /api/settings

è·å–åç«¯é…ç½®ä¿¡æ¯ã€‚

**å“åº”**ï¼š

```json
{
  "input_params": {
    "properties": {
      "prompt": {
        "default": "",
        "title": "Prompt",
        "type": "string",
        "field": "textarea"
      },
      "guidance_scale": {
        "default": 7.5,
        "title": "Guidance Scale",
        "type": "number",
        "min": 1.0,
        "max": 20.0,
        "field": "range"
      }
    }
  },
  "info": {
    "properties": {
      "title": "StreamDiffusion Backend",
      "input_mode": {
        "default": "image"
      }
    }
  },
  "max_queue_size": 0
}
```

#### GET /api/queue

è·å–é˜Ÿåˆ—çŠ¶æ€ã€‚

**å“åº”**ï¼š

```json
{
  "queue_size": 0
}
```

#### GET /api/stream/{userId}

è·å–å®æ—¶å›¾åƒæµï¼ˆmultipart/x-mixed-replaceï¼‰ã€‚

**å‚æ•°**ï¼š
- `quality`: JPEG è´¨é‡ï¼ˆ1-100ï¼‰ï¼Œé»˜è®¤ 85
- `max_fps`: æœ€å¤§å¸§ç‡ï¼Œé»˜è®¤ 30

**ç¤ºä¾‹**ï¼š

```html
<img src="http://localhost:8000/api/stream/user123?quality=85&max_fps=30" />
```

## é…ç½®è¯´æ˜

### æ¨¡å‹é…ç½®

```yaml
model:
  model_id: "stabilityai/sd-turbo"  # Hugging Face æ¨¡å‹ ID
  acceleration: "xformers"  # åŠ é€Ÿæ–¹å¼
  engine_dir: "engines"  # TensorRT å¼•æ“ç¼“å­˜ç›®å½•
  use_cuda_graph: false  # CUDA Graph ä¼˜åŒ–
```

### Pipeline é…ç½®

```yaml
pipeline:
  name: "img2img"  # Pipeline ç±»å‹
  mode: "image"  # è¾“å…¥æ¨¡å¼
  width: 512  # å›¾åƒå®½åº¦ï¼ˆå¿…é¡»æ˜¯ 8 çš„å€æ•°ï¼‰
  height: 512  # å›¾åƒé«˜åº¦ï¼ˆå¿…é¡»æ˜¯ 8 çš„å€æ•°ï¼‰
  use_tiny_vae: true  # ä½¿ç”¨ Tiny VAE
  use_lcm_lora: true  # ä½¿ç”¨ LCM LoRA
  warmup: 10  # Warmup æ­¥éª¤æ•°
```

### æ€§èƒ½é…ç½®

```yaml
performance:
  enable_similar_image_filter: false  # ç›¸ä¼¼å›¾åƒè¿‡æ»¤
  similar_image_filter_threshold: 0.98  # ç›¸ä¼¼åº¦é˜ˆå€¼
  similar_image_filter_max_skip_frame: 10  # æœ€å¤§è·³å¸§æ•°
  jpeg_quality: 85  # å›¾åƒæµ JPEG è´¨é‡
```

### ç¯å¢ƒå˜é‡

å¯ä»¥é€šè¿‡ç¯å¢ƒå˜é‡è¦†ç›–é…ç½®ï¼š

```bash
export STREAMDIFFUSION_MODEL__MODEL_ID="stabilityai/sd-turbo"
export STREAMDIFFUSION_MODEL__ACCELERATION="xformers"
export STREAMDIFFUSION_PIPELINE__WIDTH=512
export STREAMDIFFUSION_PIPELINE__HEIGHT=512
```

## åŠ é€Ÿæ–¹å¼

### xformersï¼ˆæ¨èï¼‰

æœ€ç®€å•çš„åŠ é€Ÿæ–¹å¼ï¼Œæ˜¾è‘—é™ä½æ˜¾å­˜å ç”¨ã€‚

```bash
pip install -r requirements-xformers.txt
```

é…ç½®ï¼š

```yaml
model:
  acceleration: "xformers"
```

### TensorRT

æœ€é«˜æ€§èƒ½ï¼Œä½†é¦–æ¬¡è¿è¡Œéœ€è¦ç¼–è¯‘å¼•æ“ï¼ˆ5-10 åˆ†é’Ÿï¼‰ã€‚

```bash
pip install -r requirements-tensorrt.txt
```

é…ç½®ï¼š

```yaml
model:
  acceleration: "tensorrt"
  engine_dir: "engines"
  use_cuda_graph: true  # å¯é€‰ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–
```

**æ³¨æ„**ï¼š
- å¼•æ“ä¼šç¼“å­˜åœ¨ `engine_dir` ç›®å½•
- æ›´æ”¹æ¨¡å‹ã€å°ºå¯¸æˆ– batch_size éœ€è¦é‡æ–°ç¼–è¯‘
- prompt ç­‰è¿è¡Œæ—¶å‚æ•°å¯ä»¥åŠ¨æ€æ›´æ–°

### æ— åŠ é€Ÿ

ä½¿ç”¨é»˜è®¤ PyTorch å®ç°ã€‚

```yaml
model:
  acceleration: "none"
```

## æ•…éšœæ’é™¤

### CUDA å†…å­˜ä¸è¶³

- é™ä½å›¾åƒå°ºå¯¸ï¼ˆwidth/heightï¼‰
- ä½¿ç”¨ Tiny VAE
- å¯ç”¨ xformers

### TensorRT ç¼–è¯‘å¤±è´¥

- æ£€æŸ¥ CUDA ç‰ˆæœ¬å…¼å®¹æ€§
- ç¡®ä¿å®‰è£…äº†æ­£ç¡®çš„ TensorRT ç‰ˆæœ¬
- æŸ¥çœ‹æ—¥å¿—è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯

### ä¾èµ–ç‰ˆæœ¬å†²çª

è¿è¡Œä¾èµ–æ£€æŸ¥ï¼š

```python
from app.core.dependencies import DependencyChecker

checker = DependencyChecker()
is_valid, errors = checker.check_all("xformers")

if not is_valid:
    for error in errors:
        print(error)
    
    recommended = checker.get_recommended_versions("xformers")
    print("æ¨èç‰ˆæœ¬:", recommended)
```

## æ€§èƒ½ä¼˜åŒ–

### ç›¸ä¼¼å›¾åƒè¿‡æ»¤

è·³è¿‡ç›¸ä¼¼åº¦è¿‡é«˜çš„å¸§ä»¥èŠ‚çœè®¡ç®—ï¼š

```yaml
performance:
  enable_similar_image_filter: true
  similar_image_filter_threshold: 0.98
  similar_image_filter_max_skip_frame: 10
```

### GPU å†…å­˜ç®¡ç†

ç³»ç»Ÿä¼šè‡ªåŠ¨æ¸…ç† GPU å†…å­˜ï¼Œä¹Ÿå¯ä»¥æ‰‹åŠ¨è§¦å‘ï¼š

```python
from app.utils.performance import PerformanceOptimizer

PerformanceOptimizer.cleanup_gpu_memory()
PerformanceOptimizer.log_gpu_memory_info()
```

## å¼€å‘

### é¡¹ç›®ç»“æ„

```
app/
â”œâ”€â”€ main.py                 # FastAPI åº”ç”¨å…¥å£
â”œâ”€â”€ config/                 # é…ç½®ç®¡ç†
â”‚   â”œâ”€â”€ settings.py
â”‚   â””â”€â”€ config.yaml
â”œâ”€â”€ core/                   # æ ¸å¿ƒç»„ä»¶
â”‚   â”œâ”€â”€ engine.py          # StreamDiffusion å¼•æ“
â”‚   â”œâ”€â”€ session.py         # ä¼šè¯ç®¡ç†
â”‚   â””â”€â”€ dependencies.py    # ä¾èµ–æ£€æŸ¥
â”œâ”€â”€ api/                    # API å±‚
â”‚   â”œâ”€â”€ websocket.py       # WebSocket å¤„ç†
â”‚   â”œâ”€â”€ http.py            # HTTP API
â”‚   â””â”€â”€ stream.py          # å›¾åƒæµ
â”œâ”€â”€ pipelines/              # Pipeline å®ç°
â”‚   â”œâ”€â”€ base.py
â”‚   â”œâ”€â”€ img2img.py
â”‚   â””â”€â”€ txt2img.py
â””â”€â”€ utils/                  # å·¥å…·å‡½æ•°
    â”œâ”€â”€ image.py
    â”œâ”€â”€ performance.py
    â””â”€â”€ logger.py
```

### æ·»åŠ æ–° Pipeline

1. åœ¨ `app/pipelines/` åˆ›å»ºæ–°æ–‡ä»¶
2. ç»§æ‰¿ `BasePipeline` å¹¶å®ç°æ‰€æœ‰æŠ½è±¡æ–¹æ³•
3. ç±»åå¿…é¡»ä¸º `Pipeline`
4. åœ¨é…ç½®ä¸­æŒ‡å®š Pipeline åç§°

ç¤ºä¾‹ï¼š

```python
from app.pipelines.base import BasePipeline

class Pipeline(BasePipeline):
    # å®ç°æ‰€æœ‰æŠ½è±¡æ–¹æ³•
    pass
```

## è®¸å¯è¯

[æ·»åŠ è®¸å¯è¯ä¿¡æ¯]

## è‡´è°¢

- [StreamDiffusion](https://github.com/cumulo-autumn/StreamDiffusion)
- [Stable Diffusion](https://github.com/Stability-AI/stablediffusion)
- [FastAPI](https://fastapi.tiangolo.com/)
