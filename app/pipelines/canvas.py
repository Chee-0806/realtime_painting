"""
é‡æ„åçš„ img2img Pipeline

åŸºäº StreamDiffusionBasePipelineï¼Œä¸“æ³¨äºç”»å¸ƒæ¨¡å¼çš„å›¾åƒç”Ÿæˆã€‚
æ”¯æŒ ControlNet é›†æˆã€‚
"""

import logging
import cv2
import numpy as np
import torch
from typing import Any, Dict, List, Optional
from PIL import Image
from pydantic import BaseModel, Field

from app.pipelines.streamdiffusion_base import StreamDiffusionBasePipeline
from app.config import get_config

try:
    from controlnet_aux import (
        CannyDetector,
        OpenposeDetector,
        MidasDetector,
        HEDdetector,
        MLSDdetector,
        LineartDetector,
        NormalBaeDetector,
        PidiNetDetector,  # ä¿®æ­£ï¼šä¸æ˜¯ ScribbleDetector
        SamDetector,
    )
    CONTROLNET_AUX_AVAILABLE = True
    logging.info("âœ… controlnet-aux å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    CONTROLNET_AUX_AVAILABLE = False
    logging.warning(f"controlnet-aux import failed: {e}, ControlNet functionality will be limited")


class Pipeline(StreamDiffusionBasePipeline):
    """
    img2img Pipeline - ç”»å¸ƒæ¨¡å¼ä¸“ç”¨

    é€‚ç”¨äºï¼š
    - ç”»å¸ƒç»˜åˆ¶åˆ°å›¾åƒç”Ÿæˆ
    - å±€éƒ¨ä¿®æ”¹å’Œå¢å¼º
    - è‰ºæœ¯åˆ›ä½œè¾…åŠ©
    - ControlNet ç²¾ç¡®æ§åˆ¶
    """

    class Info(BaseModel):
        name: str = "StreamDiffusion img2img (Canvas Mode with ControlNet)"
        input_mode: str = "image"
        page_content: str = """
        <h1 class="text-3xl font-bold">Canvas Image Generation with ControlNet</h1>
        <h3 class="text-xl font-bold">Image-to-Image SD-Turbo for Canvas Drawing with Precise Control</h3>
        <p class="text-sm">
            This demo showcases
            <a
            href="https://github.com/cumulo-autumn/StreamDiffusion"
            target="_blank"
            class="text-blue-500 underline hover:no-underline">StreamDiffusion</a>
            Image to Image pipeline using
            <a
            href="https://huggingface.co/stabilityai/sd-turbo"
            target="_blank"
            class="text-blue-500 underline hover:no-underline">SD-Turbo</a>
            with ControlNet support for precise artistic control.
        </p>
        <h2>Features</h2>
        <ul class="list-disc list-inside text-sm">
            <li>Canvas-to-image generation</li>
            <li>LoRA support for different styles</li>
            <li>Real-time parameter adjustment</li>
            <li>High quality output for artistic work</li>
            <li><strong>ControlNet integration for precise control</strong></li>
            <li>Multiple ControlNet support</li>
            <li>Edge detection, pose estimation, depth mapping</li>
        </ul>
        <h2>Use Cases</h2>
        <ul class="list-disc list-inside text-sm">
            <li>Digital painting assistance</li>
            <li>Sketch to image conversion</li>
            <li>Art style transfer</li>
            <li>Concept visualization</li>
            <li>Pose-controlled character creation</li>
            <li>Structure-preserving editing</li>
        </ul>
        """

    class InputParams(StreamDiffusionBasePipeline.InputParams):
        """img2img ç‰¹å®šçš„è¾“å…¥å‚æ•°ï¼ˆåŒ…å« ControlNet æ”¯æŒï¼‰"""
        # ControlNet åŸºç¡€æ§åˆ¶
        controlnet_enabled: bool = Field(
            False,
            title="å¯ç”¨ ControlNet",
            id="controlnet_enabled",
            field="checkbox"
        )

        controlnet_model: str = Field(
            "canny",
            title="ControlNet ç±»å‹",
            id="controlnet_model",
            field="select",
            values=["canny", "depth", "pose", "scribble", "lineart", "normal", "semantic", "mlsd", "hed"]
        )

        controlnet_strength: float = Field(
            1.0,
            min=0.0,
            max=2.0,
            step=0.1,
            title="ControlNet å¼ºåº¦",
            id="controlnet_strength",
            field="range"
        )

        # Canny ç‰¹å®šå‚æ•°
        canny_low_threshold: int = Field(
            50,
            min=0,
            max=255,
            title="Canny ä½é˜ˆå€¼",
            id="canny_low_threshold",
            hide=True
        )

        canny_high_threshold: int = Field(
            100,
            min=0,
            max=255,
            title="Canny é«˜é˜ˆå€¼",
            id="canny_high_threshold",
            hide=True
        )

        # å¤š ControlNet é…ç½®ï¼ˆä» API ä¼ å…¥ï¼‰
        multi_controlnet_configs: Optional[List[Dict[str, Any]]] = Field(
            None,
            title="å¤š ControlNet é…ç½®",
            id="multi_controlnet_configs",
            hide=True
        )

    def __init__(self, args: Dict[str, Any], device: torch.device, torch_dtype: torch.dtype):
        super().__init__(args, device, torch_dtype)
        self.controlnet_processors = {}
        self._init_controlnet_processors()

    def _init_controlnet_processors(self):
        """åˆå§‹åŒ– ControlNet é¢„å¤„ç†å™¨"""
        self.logger.info("ğŸ”§ å¼€å§‹åˆå§‹åŒ– ControlNet é¢„å¤„ç†å™¨...")

        if not CONTROLNET_AUX_AVAILABLE:
            self.logger.warning("âŒ controlnet-aux æœªå®‰è£…ï¼Œä½¿ç”¨åŸºç¡€é¢„å¤„ç†å™¨")
            return

        try:
            # åˆå§‹åŒ–æ‰€æœ‰å¯ç”¨çš„é¢„å¤„ç†å™¨
            self.controlnet_processors = {}

            # Canny è¾¹ç¼˜æ£€æµ‹
            try:
                self.controlnet_processors["canny"] = CannyDetector()
                self.logger.info("âœ… Canny è¾¹ç¼˜æ£€æµ‹é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ Canny é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # Openpose å§¿æ€æ£€æµ‹
            try:
                self.controlnet_processors["pose"] = OpenposeDetector()
                self.logger.info("âœ… Openpose å§¿æ€æ£€æµ‹é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ Openpose é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # Midas æ·±åº¦æ£€æµ‹
            try:
                self.controlnet_processors["depth"] = MidasDetector()
                self.logger.info("âœ… Midas æ·±åº¦æ£€æµ‹é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ Midas é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # HED è¾¹ç¼˜æ£€æµ‹
            try:
                self.controlnet_processors["hed"] = HEDdetector()
                self.logger.info("âœ… HED è¾¹ç¼˜æ£€æµ‹é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ HED é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # MLSD çº¿æ¡æ£€æµ‹
            try:
                self.controlnet_processors["mlsd"] = MLSDdetector()
                self.logger.info("âœ… MLSD çº¿æ¡æ£€æµ‹é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ MLSD é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # Lineart çº¿æ¡è‰ºæœ¯
            try:
                self.controlnet_processors["lineart"] = LineartDetector()
                self.logger.info("âœ… Lineart çº¿æ¡è‰ºæœ¯é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ Lineart é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # NormalBae æ³•çº¿å›¾
            try:
                self.controlnet_processors["normal"] = NormalBaeDetector()
                self.logger.info("âœ… NormalBae æ³•çº¿å›¾é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ NormalBae é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # PidiNet æ¶‚é¸¦æ£€æµ‹
            try:
                self.controlnet_processors["scribble"] = PidiNetDetector()
                self.logger.info("âœ… PidiNet æ¶‚é¸¦æ£€æµ‹é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ PidiNet é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            # SAM åˆ†å‰²
            try:
                self.controlnet_processors["semantic"] = SamDetector()
                self.logger.info("âœ… SAM è¯­ä¹‰åˆ†å‰²é¢„å¤„ç†å™¨åˆå§‹åŒ–æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"âŒ SAM é¢„å¤„ç†å™¨åˆå§‹åŒ–å¤±è´¥: {e}")

            self.logger.info(f"ğŸ‰ ControlNet é¢„å¤„ç†å™¨åˆå§‹åŒ–å®Œæˆï¼æˆåŠŸåˆå§‹åŒ– {len(self.controlnet_processors)} ä¸ªé¢„å¤„ç†å™¨")
            self.logger.info(f"ğŸ“‹ å¯ç”¨çš„ ControlNet ç±»å‹: {list(self.controlnet_processors.keys())}")

        except Exception as e:
            self.logger.error(f"ğŸ’¥ åˆå§‹åŒ– ControlNet é¢„å¤„ç†å™¨æ—¶å‘ç”Ÿä¸¥é‡é”™è¯¯: {e}")
            self.controlnet_processors = {}

    def _get_initial_params(self) -> "Pipeline.InputParams":
        """è·å– canvas ç‰¹å®šçš„åˆå§‹å‚æ•°"""
        config = get_config()
        canvas_gen = config.canvas_generation
        return self.InputParams(
            prompt=canvas_gen.prompt,
            negative_prompt=canvas_gen.negative_prompt,
            width=canvas_gen.width,
            height=canvas_gen.height,
            steps=canvas_gen.steps,
            cfg_scale=canvas_gen.cfg_scale,
            denoise=canvas_gen.denoise,
            seed=canvas_gen.seed,
            lora_selection="none",
            controlnet_enabled=config.model.controlnet.enabled,
            controlnet_model=config.model.controlnet.preprocessor,
            controlnet_strength=config.model.controlnet.conditioning_scale,
            canny_low_threshold=config.model.controlnet.canny_low_threshold,
            canny_high_threshold=config.model.controlnet.canny_high_threshold
        )

    def _get_pipeline_config(self, params: "Pipeline.InputParams") -> Dict[str, Any]:
        """è·å– canvas ç®¡é“ç‰¹å®šé…ç½®"""
        config = get_config()
        canvas_perf = config.canvas_performance
        return {
            "mode": "img2img",
            "enable_similar_image_filter": canvas_perf.enable_similar_image_filter,
            "similar_image_filter_threshold": canvas_perf.similar_image_filter_threshold,
            "similar_image_filter_max_skip_frame": canvas_perf.similar_image_filter_max_skip_frame,
            "frame_buffer_size": canvas_perf.frame_buffer_size,
        }

    def _apply_controlnet_preprocessing(self, image: Image.Image, params: "Pipeline.InputParams") -> Image.Image:
        """åº”ç”¨ ControlNet é¢„å¤„ç†"""
        self.logger.info(f"ğŸ›ï¸ ControlNet é¢„å¤„ç†å¼€å§‹ - å¯ç”¨çŠ¶æ€: {params.controlnet_enabled}")

        if not params.controlnet_enabled:
            self.logger.info("â­ï¸ ControlNet æœªå¯ç”¨ï¼Œè·³è¿‡é¢„å¤„ç†")
            return image

        processor_type = params.controlnet_model
        self.logger.info(f"ğŸ”§ ä½¿ç”¨çš„ ControlNet ç±»å‹: {processor_type}")
        self.logger.info(f"ğŸ“ è¾“å…¥å›¾åƒå°ºå¯¸: {image.size}, æ¨¡å¼: {image.mode}")

        if processor_type not in self.controlnet_processors:
            available_types = list(self.controlnet_processors.keys())
            self.logger.error(f"âŒ æœªçŸ¥çš„ ControlNet æ¨¡å‹: {processor_type}")
            self.logger.error(f"âŒ å¯ç”¨çš„ ControlNet ç±»å‹: {available_types}")
            return image

        try:
            processor = self.controlnet_processors[processor_type]
            self.logger.info(f"âœ… æˆåŠŸè·å– {processor_type} å¤„ç†å™¨")

            # è½¬æ¢ä¸º RGB æ ¼å¼
            original_mode = image.mode
            if image.mode != 'RGB':
                image = image.convert('RGB')
                self.logger.info(f"ğŸ”„ å›¾åƒæ ¼å¼è½¬æ¢: {original_mode} -> RGB")

            # ç‰¹æ®Šå¤„ç† Canny è¾¹ç¼˜æ£€æµ‹
            if processor_type == "canny":
                self.logger.info(f"âš¡ åº”ç”¨ Canny è¾¹ç¼˜æ£€æµ‹ - ä½é˜ˆå€¼: {params.canny_low_threshold}, é«˜é˜ˆå€¼: {params.canny_high_threshold}")
                return self._apply_canny_preprocessing(image, params)
            else:
                self.logger.info(f"ğŸ¨ åº”ç”¨ {processor_type} é¢„å¤„ç†...")
                # ä½¿ç”¨ controlnet-aux å¤„ç†å™¨
                processed_image = processor(image)
                self.logger.info(f"âœ… {processor_type} å¤„ç†å®Œæˆ")

                # ç¡®ä¿è¾“å‡ºæ˜¯ PIL Image
                if isinstance(processed_image, np.ndarray):
                    self.logger.info(f"ğŸ”„ è½¬æ¢ numpy array åˆ° PIL Image")
                    self.logger.info(f"ğŸ“ é¢„å¤„ç†åå›¾åƒå°ºå¯¸ (numpy): {processed_image.shape}")
                    processed_image = Image.fromarray(processed_image)
                elif hasattr(processed_image, 'image'):  # æŸäº›å¤„ç†å™¨è¿”å›å¸¦æœ‰ .image å±æ€§çš„å¯¹è±¡
                    self.logger.info(f"ğŸ”„ ä»å¯¹è±¡æå– .image å±æ€§")
                    processed_image = processed_image.image

                # è½¬æ¢ä¸º RGB
                processed_mode = processed_image.mode
                if processed_image.mode != 'RGB':
                    processed_image = processed_image.convert('RGB')
                    self.logger.info(f"ğŸ”„ é¢„å¤„ç†åå›¾åƒæ ¼å¼è½¬æ¢: {processed_mode} -> RGB")

                self.logger.info(f"ğŸ“ æœ€ç»ˆè¾“å‡ºå›¾åƒå°ºå¯¸: {processed_image.size}, æ¨¡å¼: {processed_image.mode}")
                return processed_image

        except Exception as e:
            self.logger.error(f"ğŸ’¥ ControlNet é¢„å¤„ç†å¤±è´¥ ({processor_type}): {e}")
            self.logger.error(f"ğŸ’¥ é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")
            return image

    def _apply_canny_preprocessing(self, image: Image.Image, params: "Pipeline.InputParams") -> Image.Image:
        """åº”ç”¨ Canny è¾¹ç¼˜æ£€æµ‹é¢„å¤„ç†"""
        try:
            self.logger.info(f"ğŸ” å¼€å§‹ Canny è¾¹ç¼˜æ£€æµ‹é¢„å¤„ç†")
            self.logger.info(f"ğŸ“ åŸå§‹å›¾åƒå°ºå¯¸: {image.size}, æ¨¡å¼: {image.mode}")

            # è½¬æ¢ä¸º numpy æ•°ç»„
            img_array = np.array(image)
            self.logger.info(f"ğŸ”„ è½¬æ¢ä¸º numpy æ•°ç»„ï¼Œå½¢çŠ¶: {img_array.shape}, æ•°æ®ç±»å‹: {img_array.dtype}")

            # åº”ç”¨ Canny è¾¹ç¼˜æ£€æµ‹
            self.logger.info(f"âš¡ æ‰§è¡Œ Canny è¾¹ç¼˜æ£€æµ‹ - ä½é˜ˆå€¼: {params.canny_low_threshold}, é«˜é˜ˆå€¼: {params.canny_high_threshold}")
            edges = cv2.Canny(
                img_array,
                params.canny_low_threshold,
                params.canny_high_threshold
            )
            self.logger.info(f"âœ… Canny æ£€æµ‹å®Œæˆï¼Œè¾¹ç¼˜å›¾åƒå½¢çŠ¶: {edges.shape}")

            # ç»Ÿè®¡è¾¹ç¼˜åƒç´ 
            edge_pixels = np.sum(edges > 0)
            total_pixels = edges.size
            edge_ratio = edge_pixels / total_pixels * 100
            self.logger.info(f"ğŸ“Š è¾¹ç¼˜ç»Ÿè®¡: {edge_pixels}/{total_pixels} åƒç´  ({edge_ratio:.2f}%) æ˜¯è¾¹ç¼˜")

            # è½¬æ¢å› PIL å›¾åƒ
            self.logger.info(f"ğŸ”„ è½¬æ¢è¾¹ç¼˜æ£€æµ‹ç»“æœåˆ° PIL å›¾åƒ")
            control_image = Image.fromarray(edges, mode='L').convert('RGB')
            self.logger.info(f"ğŸ“ æœ€ç»ˆæ§åˆ¶å›¾åƒå°ºå¯¸: {control_image.size}, æ¨¡å¼: {control_image.mode}")

            return control_image
        except Exception as e:
            self.logger.error(f"ğŸ’¥ Canny é¢„å¤„ç†å¤±è´¥: {e}")
            self.logger.error(f"ğŸ’¥ é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")
            return image

    def _decode_base64_image(self, base64_str: str) -> Optional[Image.Image]:
        """è§£ç  Base64 å›¾åƒ"""
        try:
            import base64
            import io

            # ç§»é™¤å¯èƒ½çš„æ•°æ®URLå‰ç¼€
            if base64_str.startswith('data:image'):
                base64_str = base64_str.split(',')[1]

            image_data = base64.b64decode(base64_str)
            image = Image.open(io.BytesIO(image_data))

            # è½¬æ¢ä¸º RGB æ ¼å¼
            if image.mode != 'RGB':
                image = image.convert('RGB')

            return image
        except Exception as e:
            self.logger.error(f"è§£ç  Base64 å›¾åƒå¤±è´¥: {e}")
            return None

    def _image_to_tensor(self, image: Image.Image) -> torch.Tensor:
        """å°† PIL å›¾åƒè½¬æ¢ä¸ºå¼ é‡"""
        if image.mode != 'RGB':
            image = image.convert('RGB')

        # è½¬æ¢ä¸º numpy æ•°ç»„
        img_array = np.array(image).astype(np.float32) / 255.0

        # è½¬æ¢ç»´åº¦é¡ºåº (H, W, C) -> (C, H, W)
        img_array = np.transpose(img_array, (2, 0, 1))

        # è½¬æ¢ä¸º PyTorch å¼ é‡å¹¶æ·»åŠ  batch ç»´åº¦
        tensor = torch.from_numpy(img_array).unsqueeze(0)

        return tensor.to(self._device)

    def _preprocess_input_image(self, params: "Pipeline.InputParams"):
        """
        é¢„å¤„ç†ç”»å¸ƒè¾“å…¥å›¾åƒï¼ˆæ”¯æŒ ControlNetï¼‰

        Args:
            params: åŒ…å«å›¾åƒå’Œå‚æ•°çš„è¾“å…¥å¯¹è±¡

        Returns:
            é¢„å¤„ç†åçš„å›¾åƒå¼ é‡æˆ–åŒ…å«æ§åˆ¶ä¿¡æ¯çš„å­—å…¸
        """
        self.logger.info("ğŸ“¸ å¼€å§‹é¢„å¤„ç†è¾“å…¥å›¾åƒ...")

        if not hasattr(params, 'image') or params.image is None:
            self.logger.error("âŒ img2img pipeline éœ€è¦è¾“å…¥å›¾åƒ")
            raise ValueError("img2img pipeline requires an input image")

        canvas_image = params.image
        self.logger.info(f"ğŸ“Š åŸå§‹ç”»å¸ƒå›¾åƒå°ºå¯¸: {canvas_image.size}, æ¨¡å¼: {canvas_image.mode}")
        self.logger.info(f"ğŸ¯ ç›®æ ‡å°ºå¯¸: {params.width}x{params.height}")

        # å¦‚æœå¯ç”¨äº†å¤š ControlNet
        if params.multi_controlnet_configs and len(params.multi_controlnet_configs) > 0:
            self.logger.info(f"ğŸ›ï¸ å¤„ç†å¤š ControlNet é…ç½® - æ•°é‡: {len(params.multi_controlnet_configs)}")

            control_images = []
            controlnet_scales = []

            for i, config in enumerate(params.multi_controlnet_configs):
                self.logger.info(f"ğŸ›ï¸ å¤„ç† ControlNet {i+1}/{len(params.multi_controlnet_configs)}")
                self.logger.info(f"   ç±»å‹: {config.get('type', 'unknown')}")
                self.logger.info(f"   æƒé‡: {config.get('weight', 1.0)}")

                # è§£ç æ§åˆ¶å›¾åƒ
                base64_image = config.get("image", "")
                if base64_image:
                    self.logger.info(f"   ğŸ“¦ è§£ç  Base64 æ§åˆ¶å›¾åƒ (é•¿åº¦: {len(base64_image)})")
                    control_image = self._decode_base64_image(base64_image)
                    if control_image:
                        self.logger.info(f"   ğŸ“ æ§åˆ¶å›¾åƒåŸå§‹å°ºå¯¸: {control_image.size}")

                        # è°ƒæ•´å¤§å°åŒ¹é…ç”»å¸ƒ
                        control_image = control_image.resize(
                            (params.width, params.height),
                            Image.Resampling.LANCZOS
                        )
                        self.logger.info(f"   ğŸ“ æ§åˆ¶å›¾åƒè°ƒæ•´åå°ºå¯¸: {control_image.size}")

                        # åº”ç”¨å¯¹åº”çš„é¢„å¤„ç†å™¨
                        cn_type = config.get("type", "canny")
                        temp_params = self.InputParams(
                            controlnet_enabled=True,
                            controlnet_model=cn_type,
                            canny_low_threshold=config.get("canny_low_threshold", 50),
                            canny_high_threshold=config.get("canny_high_threshold", 100)
                        )

                        self.logger.info(f"   ğŸ¨ åº”ç”¨ {cn_type} é¢„å¤„ç†å™¨...")
                        processed_image = self._apply_controlnet_preprocessing(control_image, temp_params)
                        self.logger.info(f"   ğŸ“ é¢„å¤„ç†åæ§åˆ¶å›¾åƒå°ºå¯¸: {processed_image.size}")
                        control_images.append(processed_image)
                        controlnet_scales.append(config.get("weight", 1.0))
                    else:
                        self.logger.error(f"   âŒ ControlNet {i+1} å›¾åƒè§£ç å¤±è´¥")
                else:
                    self.logger.warning(f"   âš ï¸ ControlNet {i+1} æ²¡æœ‰å›¾åƒæ•°æ®")

            if control_images:
                self.logger.info(f"âœ… æˆåŠŸå¤„ç† {len(control_images)} ä¸ª ControlNet")
                canvas_tensor = self._image_to_tensor(canvas_image)
                self.logger.info(f"ğŸ“Š ç”»å¸ƒå¼ é‡å½¢çŠ¶: {canvas_tensor.shape}")

                control_tensors = []
                for i, img in enumerate(control_images):
                    ctrl_tensor = self._image_to_tensor(img)
                    control_tensors.append(ctrl_tensor)
                    self.logger.info(f"ğŸ“Š æ§åˆ¶å¼ é‡ {i+1} å½¢çŠ¶: {ctrl_tensor.shape}")

                return {
                    "image": canvas_tensor,
                    "control_images": control_tensors,
                    "controlnet_conditioning_scales": controlnet_scales
                }
            else:
                self.logger.warning("âš ï¸ æ²¡æœ‰æœ‰æ•ˆçš„ ControlNet å›¾åƒï¼Œå›é€€åˆ°å•ä¸ª ControlNet æˆ–æ ‡å‡†æ¨¡å¼")

        # å¦‚æœå¯ç”¨å•ä¸ª ControlNet
        if params.controlnet_enabled:
            self.logger.info(f"ğŸ›ï¸ å¤„ç†å•ä¸ª ControlNet - ç±»å‹: {params.controlnet_model}, å¼ºåº¦: {params.controlnet_strength}")
            self.logger.info(f"ğŸ¨ åº”ç”¨ {params.controlnet_model} é¢„å¤„ç†å™¨åˆ°ç”»å¸ƒå›¾åƒ...")
            control_image = self._apply_controlnet_preprocessing(canvas_image, params)

            canvas_tensor = self._image_to_tensor(canvas_image)
            control_tensor = self._image_to_tensor(control_image)

            self.logger.info(f"ğŸ“Š ç”»å¸ƒå¼ é‡å½¢çŠ¶: {canvas_tensor.shape}")
            self.logger.info(f"ğŸ“Š æ§åˆ¶å¼ é‡å½¢çŠ¶: {control_tensor.shape}")
            self.logger.info(f"âš–ï¸ ControlNet æ¡ä»¶ç¼©æ”¾: {params.controlnet_strength}")

            return {
                "image": canvas_tensor,
                "control_image": control_tensor,
                "controlnet_conditioning_scale": params.controlnet_strength
            }

        # æ ‡å‡† img2img å¤„ç†
        self.logger.info("ğŸ–¼ï¸ ä½¿ç”¨æ ‡å‡† img2img å¤„ç†ï¼ˆæ—  ControlNetï¼‰")
        preprocessed = self.stream.preprocess_image(canvas_image)
        if hasattr(preprocessed, 'shape'):
            self.logger.info(f"ğŸ“Š æ ‡å‡†é¢„å¤„ç†å¼ é‡å½¢çŠ¶: {preprocessed.shape}")
        return preprocessed

    def prepare(self, prompt: str = "", **kwargs):
        """
        é¢„å¤„ç†å’Œ warmup

        Args:
            prompt: åˆå§‹æç¤ºè¯
            **kwargs: å…¶ä»–å‚æ•°
        """
        # ä½¿ç”¨é»˜è®¤å‚æ•°åˆ›å»ºåˆå§‹å‡†å¤‡
        initial_params = self._get_initial_params()
        if prompt:
            initial_params.prompt = prompt

        # æ›´æ–°å…¶ä»–å‚æ•°
        for key, value in kwargs.items():
            if hasattr(initial_params, key):
                setattr(initial_params, key, value)

        self._prepare_if_needed(initial_params)

    @classmethod
    def get_info(cls) -> "Pipeline.Info":
        """è·å–ç®¡é“å…ƒä¿¡æ¯"""
        return cls.Info()

    @classmethod
    def get_input_params_schema(cls) -> dict:
        """è·å–è¾“å…¥å‚æ•°çš„ JSON Schema"""
        # ä½¿ç”¨ Pydantic çš„ schema ç”ŸæˆåŠŸèƒ½
        schema = cls.InputParams.model_json_schema()

        # è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
        properties = {}
        for field_name, field_info in schema.get("properties", {}).items():
            # è·³è¿‡éšè—å­—æ®µ
            if field_info.get("hide", False):
                continue

            properties[field_name] = {
                "default": field_info.get("default", ""),
                "title": field_info.get("title", field_name),
                "id": field_name,
                "type": field_info.get("type", "string"),
                "description": field_info.get("description", ""),
            }

            # æ·»åŠ èŒƒå›´å­—æ®µ
            if "minimum" in field_info:
                properties[field_name]["min"] = field_info["minimum"]
            if "maximum" in field_info:
                properties[field_name]["max"] = field_info["maximum"]

            # æ ¹æ®ç±»å‹è®¾ç½® field ç±»å‹
            if field_info.get("type") == "number":
                properties[field_name]["field"] = "range"
            elif field_info.get("type") == "integer":
                if field_name == "seed":
                    properties[field_name]["field"] = "input"
                else:
                    properties[field_name]["field"] = "range"
            elif field_name in ["prompt", "negative_prompt"]:
                properties[field_name]["field"] = "textarea"
            else:
                properties[field_name]["field"] = "input"

            # å¤„ç†é€‰æ‹©å­—æ®µ
            if field_name == "lora_selection" and "values" in field_info:
                properties[field_name]["values"] = field_info["values"]

        return {
            "properties": properties
        }

    # é‡å†™ predict æ–¹æ³•ä»¥æ”¯æŒ ControlNet
    def predict(self, params: "Pipeline.InputParams") -> Image.Image:
        """
        æ‰§è¡Œé¢„æµ‹ï¼ˆæ”¯æŒ ControlNetï¼‰

        Args:
            params: è¾“å…¥å‚æ•°

        Returns:
            ç”Ÿæˆçš„å›¾åƒ
        """
        self.logger.info("ğŸš€ å¼€å§‹å›¾åƒç”Ÿæˆé¢„æµ‹...")
        self.logger.info(f"âš™ï¸ å‚æ•°è®¾ç½® - ControlNetå¯ç”¨: {params.controlnet_enabled}, ç±»å‹: {params.controlnet_model}, å¼ºåº¦: {params.controlnet_strength}")

        self._ensure_stream(params)
        self._prepare_if_needed(params)

        # é¢„å¤„ç†è¾“å…¥å›¾åƒ
        self.logger.info("ğŸ“¸ å¼€å§‹é¢„å¤„ç†è¾“å…¥å›¾åƒ...")
        image_input = self._preprocess_input_image(params)

        try:
            if isinstance(image_input, dict):
                # ControlNet ç”Ÿæˆ
                if "control_images" in image_input:
                    # å¤š ControlNet
                    num_controls = len(image_input['control_images'])
                    control_types = params.multi_controlnet_configs[i].get("type", "unknown") if params.multi_controlnet_configs else "unknown"
                    self.logger.info(f"ğŸ›ï¸ ä½¿ç”¨å¤š ControlNet ç”Ÿæˆ - æ•°é‡: {num_controls}")
                    self.logger.info(f"ğŸ›ï¸ ControlNet æƒé‡: {image_input['controlnet_conditioning_scales']}")

                    for i, scale in enumerate(image_input['controlnet_conditioning_scales']):
                        cn_type = params.multi_controlnet_configs[i].get("type", "unknown") if params.multi_controlnet_configs and i < len(params.multi_controlnet_configs) else "unknown"
                        self.logger.info(f"   ğŸ›ï¸ ControlNet {i+1}: {cn_type}, æƒé‡: {scale}")

                    self.logger.info(f"ğŸ“Š ä¸»å›¾åƒå¼ é‡å½¢çŠ¶: {image_input['image'].shape}")
                    for i, ctrl_img in enumerate(image_input['control_images']):
                        self.logger.info(f"ğŸ“Š æ§åˆ¶å›¾åƒ {i+1} å¼ é‡å½¢çŠ¶: {ctrl_img.shape}")

                    self.logger.info("ğŸ¨ æ‰§è¡Œå¤š ControlNet å›¾åƒç”Ÿæˆ...")
                    output_image = self.stream(
                        image=image_input["image"],
                        control_images=image_input["control_images"],
                        controlnet_conditioning_scales=image_input["controlnet_conditioning_scales"],
                        prompt=params.prompt
                    )
                else:
                    # å•ä¸ª ControlNet
                    self.logger.info(f"ğŸ›ï¸ ä½¿ç”¨å•ä¸ª ControlNet ç”Ÿæˆ - ç±»å‹: {params.controlnet_model}, æƒé‡: {image_input['controlnet_conditioning_scale']}")
                    self.logger.info(f"ğŸ“Š ä¸»å›¾åƒå¼ é‡å½¢çŠ¶: {image_input['image'].shape}")
                    self.logger.info(f"ğŸ“Š æ§åˆ¶å›¾åƒå¼ é‡å½¢çŠ¶: {image_input['control_image'].shape}")

                    self.logger.info("ğŸ¨ æ‰§è¡Œ ControlNet å›¾åƒç”Ÿæˆ...")
                    output_image = self.stream(
                        image=image_input["image"],
                        control_image=image_input["control_image"],
                        controlnet_conditioning_scale=image_input["controlnet_conditioning_scale"],
                        prompt=params.prompt
                    )
            else:
                # æ ‡å‡† img2img ç”Ÿæˆ
                self.logger.info("ğŸ–¼ï¸ ä½¿ç”¨æ ‡å‡† img2img ç”Ÿæˆï¼ˆæ—  ControlNetï¼‰")
                if hasattr(image_input, 'shape'):
                    self.logger.info(f"ğŸ“Š è¾“å…¥å›¾åƒå¼ é‡å½¢çŠ¶: {image_input.shape}")

                self.logger.info("ğŸ¨ æ‰§è¡Œæ ‡å‡†å›¾åƒç”Ÿæˆ...")
                output_image = self.stream(
                    image=image_input,
                    prompt=params.prompt
                )

            self.logger.info("âœ… å›¾åƒç”ŸæˆæˆåŠŸå®Œæˆ!")
            if hasattr(output_image, 'size'):
                self.logger.info(f"ğŸ“ è¾“å‡ºå›¾åƒå°ºå¯¸: {output_image.size}")

            return output_image

        except Exception as e:
            self.logger.error(f"ğŸ’¥ å›¾åƒç”Ÿæˆå¤±è´¥: {e}")
            self.logger.error(f"ğŸ’¥ é”™è¯¯è¯¦æƒ…: {type(e).__name__}: {str(e)}")

            # é™çº§åˆ°æ ‡å‡†ç”Ÿæˆ
            try:
                self.logger.info("ğŸ”„ å°è¯•é™çº§åˆ°æ ‡å‡†ç”Ÿæˆæ¨¡å¼...")
                if isinstance(image_input, dict):
                    image_input = image_input["image"]
                    self.logger.info("ğŸ“Š é™çº§ä½¿ç”¨ä¸»å›¾åƒå¼ é‡")

                self.logger.info("ğŸ¨ æ‰§è¡Œé™çº§å›¾åƒç”Ÿæˆ...")
                return self.stream(image=image_input, prompt=params.prompt)
            except Exception as fallback_e:
                self.logger.error(f"ğŸ’¥ é™çº§ç”Ÿæˆä¹Ÿå¤±è´¥: {fallback_e}")
                self.logger.error(f"ğŸ’¥ é™çº§é”™è¯¯è¯¦æƒ…: {type(fallback_e).__name__}: {str(fallback_e)}")
                raise e

    def generate_with_multi_controlnet(self, **kwargs) -> Image.Image:
        """
        ä½¿ç”¨å¤šä¸ª ControlNet ç”Ÿæˆå›¾åƒçš„ä¾¿æ·æ–¹æ³•

        Args:
            **kwargs: ç”Ÿæˆå‚æ•°ï¼ŒåŒ…æ‹¬ controlnet_configs

        Returns:
            ç”Ÿæˆçš„å›¾åƒ
        """
        # åˆ›å»ºå‚æ•°å¯¹è±¡
        params = self._get_initial_params()

        # æ›´æ–°å‚æ•°
        for key, value in kwargs.items():
            if hasattr(params, key):
                setattr(params, key, value)

        # è®¾ç½®å¤š ControlNet é…ç½®
        if "controlnet_configs" in kwargs:
            params.multi_controlnet_configs = kwargs["controlnet_configs"]
            params.controlnet_enabled = True  # ç¡®ä¿ ControlNet å¯ç”¨

        # è®¾ç½®ç”»å¸ƒå›¾åƒ
        if "image" in kwargs:
            params.image = kwargs["image"]

        # æ‰§è¡Œç”Ÿæˆ
        return self.predict(params)